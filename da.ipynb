{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0K9H8Nk-N_Tf",
      "metadata": {
        "id": "0K9H8Nk-N_Tf"
      },
      "source": [
        "# Domain adaptation on classification task with AlexNet and PACS dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5q3A_omGNpCf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q3A_omGNpCf",
        "outputId": "d6496b40-dd84-4931-f53c-12cf85f71e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /home/borella/anaconda3/lib/python3.12/site-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /home/borella/anaconda3/lib/python3.12/site-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/borella/anaconda3/lib/python3.12/site-packages (from torchmetrics) (2.5.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /home/borella/anaconda3/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /home/borella/anaconda3/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: networkx in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/borella/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/borella/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/borella/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.3)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "source": [
        "# Install additional libraries\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GrQxrFD9QBIi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrQxrFD9QBIi",
        "outputId": "dcd7d382-e9e5-466c-f592-64d5079db834"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/SimoneBorella/domain-adaptation.git\n",
        "\n",
        "!cp -r ./domain-adaptation/models .\n",
        "!cp -r ./domain-adaptation/utils .\n",
        "\n",
        "!rm -r ./domain-adaptation\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e686f1d3-211d-4de8-9e34-520059da376f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e686f1d3-211d-4de8-9e34-520059da376f",
        "outputId": "124f53c2-4881-4126-9d32-8fe99130469d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10032, done.\u001b[K\n",
            "remote: Total 10032 (delta 0), reused 0 (delta 0), pack-reused 10032 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10032/10032), 174.13 MiB | 8.85 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (9993/9993), done.\n",
            "rm: remove write-protected regular file 'Homework3-PACS/.git/objects/pack/pack-593e21a0699e0596d1434535007769eaee8f5f32.idx'? ^C\n",
            "Cloning into 'DANN_Template'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23 (from 1)\u001b[K\n",
            "Receiving objects: 100% (23/23), 33.86 KiB | 990.00 KiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "rm: remove write-protected regular file 'DANN_Template/.git/objects/pack/pack-e4becacbe1d106caa2e769f6634d14d1068f1ee3.pack'? "
          ]
        }
      ],
      "source": [
        "# Download PACS Dataset Images\n",
        "!git clone https://github.com/MachineLearning2020/Homework3-PACS/\n",
        "!mkdir -p data\n",
        "!mv Homework3-PACS/PACS data/\n",
        "!rm -r Homework3-PACS/\n",
        "\n",
        "# Download PACS Dataset Labels\n",
        "!git clone https://github.com/silvia1993/DANN_Template/\n",
        "!mv DANN_Template/txt_lists/art_painting.txt data/PACS/\n",
        "!mv DANN_Template/txt_lists/cartoon.txt data/PACS/\n",
        "!mv DANN_Template/txt_lists/photo.txt data/PACS/\n",
        "!mv DANN_Template/txt_lists/sketch.txt data/PACS/\n",
        "!rm -r DANN_Template/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "46c3fbc9-679c-46a3-ae6a-d2ce96d21d43",
      "metadata": {
        "id": "46c3fbc9-679c-46a3-ae6a-d2ce96d21d43"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.backends import cudnn\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import AlexNet_Weights\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from models.alexnet import AlexNet\n",
        "from utils.monitor import Monitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vVcmrIe_TGGA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVcmrIe_TGGA",
        "outputId": "1b7ebb4d-f8d3-496a-bb2c-87143c08520b"
      },
      "outputs": [],
      "source": [
        "# Google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! mkdir -p /content/drive/MyDrive/da\n",
        "res_dir = \"/content/drive/MyDrive/da\"\n",
        "\n",
        "\n",
        "# Local\n",
        "# res_dir = \".\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2u596HRYSws5",
      "metadata": {
        "id": "2u596HRYSws5"
      },
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA available\")\n",
        "        print(f\"Number of devices: {torch.cuda.device_count()}\")\n",
        "        for dev in range(torch.cuda.device_count()):\n",
        "            print(f\"Device {dev}:\")\n",
        "            print(f\"\\tName: {torch.cuda.get_device_name(dev)}\")\n",
        "    else:\n",
        "        print(\"CUDA not available\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "mL9dN-DzSyLS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL9dN-DzSyLS",
        "outputId": "407fdda7-c2b7-4337-d314-7a34964c4db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA not available\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HUPEvN-ROSOw",
      "metadata": {
        "id": "HUPEvN-ROSOw"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "m_igi2pfOTvD",
      "metadata": {
        "id": "m_igi2pfOTvD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78023c5a3430>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEED = 17\n",
        "\n",
        "VERSION = 0\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "EPOCHS = 30          # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LAMBDA = 1e-4\n",
        "\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68dc5e59",
      "metadata": {},
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "df154e98-5188-40be-8311-832f86e14788",
      "metadata": {
        "id": "df154e98-5188-40be-8311-832f86e14788"
      },
      "outputs": [],
      "source": [
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, domain, transform, root_dir):\n",
        "        assert domain in ['photo', 'art_painting', 'cartoon', 'sketch']\n",
        "        self.examples = [] # (img_path, class_label)\n",
        "        self.T = transform\n",
        "\n",
        "        with open(f'{root_dir}/PACS/{domain}.txt', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip().split()\n",
        "            img_path = f\"{root_dir}/PACS/{line[0]}\"\n",
        "            class_label = int(line[1])\n",
        "            self.examples.append((img_path, class_label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, class_label = self.examples[index]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.T(img)\n",
        "        return img, class_label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1768e79",
      "metadata": {},
      "source": [
        "## Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4f8edb61",
      "metadata": {},
      "outputs": [],
      "source": [
        "def dataset_preprocessing():\n",
        "    dataset_transform = T.Compose([\n",
        "        T.Resize(256),\n",
        "        T.CenterCrop(224),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the Dataset object for training & testing\n",
        "    traindataset = PACSDataset(domain='cartoon', transform=dataset_transform, root_dir='./data')\n",
        "    testdataset = PACSDataset(domain='sketch', transform=dataset_transform, root_dir='./data')\n",
        "\n",
        "    # Define the DataLoaders\n",
        "    trainloader = DataLoader(traindataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "    testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, num_workers=4)\n",
        "    valloader = testloader\n",
        "\n",
        "    return trainloader, valloader, testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "85d4f41f",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader, valloader, testloader = dataset_preprocessing()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0efb1c",
      "metadata": {},
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335d5240",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = AlexNet()\n",
        "    model.load_state_dict(AlexNet_Weights.IMAGENET1K_V1.get_state_dict(progress=True), strict=False)\n",
        "    model.classifier[-1] = nn.Linear(4096, NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def save_model(model, file_name):\n",
        "    torch.save(model.state_dict(), file_name)\n",
        "\n",
        "def load_model(model, file_name, device=\"cuda\"):\n",
        "    model.load_state_dict(torch.load(file_name, map_location=torch.device(device)))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ceefb",
      "metadata": {},
      "source": [
        "## Loss function definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc33e58",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_loss_function():\n",
        "    return nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f5a5ca",
      "metadata": {},
      "source": [
        "## Optimizer definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a39fa9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_optimizer(model):\n",
        "    return torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94cede0",
      "metadata": {},
      "source": [
        "## Scheduler definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b786dd6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_scheduler(optimizer):\n",
        "    return optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62f3df83",
      "metadata": {},
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8730432",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_metrics(\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies, learning_rates, model_number, base_dir\n",
        "):\n",
        "    fig = plt.figure()\n",
        "    plt.title(\"Loss\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.plot(train_losses, label=\"Train Loss\")\n",
        "    plt.plot(val_losses, label=\"Val Loss\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{base_dir}/plots/loss_{model_number}.pdf\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{base_dir}/plots/accuracy_{model_number}.pdf\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.title(\"Learning rate\")\n",
        "    plt.ylabel(\"learning rate\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.plot(learning_rates, label=\"Learning Rate\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{base_dir}/plots/learning_rate_{model_number}.pdf\")\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b760999",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c052ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_baseline(model, model_number, trainloader, valloader, loss_function, optimizer, scheduler, device, monitor, base_dir):\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    learning_rates = []\n",
        "\n",
        "    best_val_loss = None\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        monitor.start(desc=f\"Epoch {e + 1}/{EPOCHS}\", max_progress=len(trainloader))\n",
        "\n",
        "        learning_rate = scheduler.get_last_lr()[0]\n",
        "        learning_rates.append(learning_rate)\n",
        "\n",
        "        train_loss = 0.0\n",
        "        cumulative_loss = 0.0\n",
        "        count_loss = 0\n",
        "\n",
        "        train_accuracy = 0.0\n",
        "        correct_predictions = 0\n",
        "        count_predictions = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = model(inputs)\n",
        "\n",
        "            loss = loss_function(logits, labels)\n",
        "\n",
        "            cumulative_loss += loss.item()\n",
        "            count_loss += 1\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss = cumulative_loss / count_loss\n",
        "\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            count_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            train_accuracy = correct_predictions / count_predictions\n",
        "\n",
        "            monitor.update(\n",
        "                i + 1,\n",
        "                learning_rate=f\"{learning_rate:.5f}\",\n",
        "                train_loss=f\"{train_loss:.4f}\",\n",
        "                train_accuracy=f\"{train_accuracy:.4f}\",\n",
        "            )\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        monitor.stop()\n",
        "\n",
        "        if valloader is not None:\n",
        "            monitor.start(desc=f\"Validation\", max_progress=len(valloader))\n",
        "\n",
        "            val_loss = 0.0\n",
        "            cumulative_loss = 0.0\n",
        "            count_loss = 0\n",
        "\n",
        "            val_accuracy = 0.0\n",
        "            correct_predictions = 0\n",
        "            count_predictions = 0\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(valloader):\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logits, _ = model(inputs)\n",
        "                    loss = loss_function(logits, labels)\n",
        "                    cumulative_loss += loss.item()\n",
        "                    count_loss += 1\n",
        "                    val_loss = cumulative_loss / count_loss\n",
        "                    predicted_labels = torch.argmax(logits, dim=1)\n",
        "                    count_predictions += labels.size(0)\n",
        "                    correct_predictions += (predicted_labels == labels).sum().item()\n",
        "                    val_accuracy = correct_predictions / count_predictions\n",
        "                    monitor.update(\n",
        "                        i + 1,\n",
        "                        val_loss=f\"{val_loss:.4f}\",\n",
        "                        val_accuracy=f\"{val_accuracy:.4f}\",\n",
        "                    )\n",
        "\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            monitor.stop()\n",
        "\n",
        "            if best_val_loss is None or val_loss < best_val_loss:\n",
        "                save_model(model, f\"{base_dir}/weights/best_{model_number}.pt\")\n",
        "                monitor.log(f\"Model saved as best_{model_number}.pt\\n\")\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        save_model(model, f\"{base_dir}/weights/last_{model_number}.pt\")\n",
        "\n",
        "        plot_training_metrics(\n",
        "            train_losses,\n",
        "            val_losses,\n",
        "            train_accuracies,\n",
        "            val_accuracies,\n",
        "            learning_rates,\n",
        "            model_number,\n",
        "            base_dir,\n",
        "        )\n",
        "\n",
        "    monitor.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57392d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_dann(model, model_number, trainloader, valloader, loss_function, optimizer, scheduler, device, monitor, base_dir):\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    learning_rates = []\n",
        "\n",
        "    best_val_loss = None\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        monitor.start(desc=f\"Epoch {e + 1}/{EPOCHS}\", max_progress=len(trainloader))\n",
        "\n",
        "        learning_rate = scheduler.get_last_lr()[0]\n",
        "        learning_rates.append(learning_rate)\n",
        "\n",
        "        train_loss = 0.0\n",
        "        cumulative_loss = 0.0\n",
        "        count_loss = 0\n",
        "\n",
        "        train_accuracy = 0.0\n",
        "        correct_predictions = 0\n",
        "        count_predictions = 0\n",
        "\n",
        "        model.train()\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = model(inputs)\n",
        "\n",
        "            loss = loss_function(logits, labels)\n",
        "\n",
        "            cumulative_loss += loss.item()\n",
        "            count_loss += 1\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss = cumulative_loss / count_loss\n",
        "\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            count_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            train_accuracy = correct_predictions / count_predictions\n",
        "\n",
        "            monitor.update(\n",
        "                i + 1,\n",
        "                learning_rate=f\"{learning_rate:.5f}\",\n",
        "                train_loss=f\"{train_loss:.4f}\",\n",
        "                train_accuracy=f\"{train_accuracy:.4f}\",\n",
        "            )\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        monitor.stop()\n",
        "\n",
        "        if valloader is not None:\n",
        "            monitor.start(desc=f\"Validation\", max_progress=len(valloader))\n",
        "\n",
        "            val_loss = 0.0\n",
        "            cumulative_loss = 0.0\n",
        "            count_loss = 0\n",
        "\n",
        "            val_accuracy = 0.0\n",
        "            correct_predictions = 0\n",
        "            count_predictions = 0\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for i, (inputs, labels) in enumerate(valloader):\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logits, _ = model(inputs)\n",
        "                    loss = loss_function(logits, labels)\n",
        "                    cumulative_loss += loss.item()\n",
        "                    count_loss += 1\n",
        "                    val_loss = cumulative_loss / count_loss\n",
        "                    predicted_labels = torch.argmax(logits, dim=1)\n",
        "                    count_predictions += labels.size(0)\n",
        "                    correct_predictions += (predicted_labels == labels).sum().item()\n",
        "                    val_accuracy = correct_predictions / count_predictions\n",
        "                    monitor.update(\n",
        "                        i + 1,\n",
        "                        val_loss=f\"{val_loss:.4f}\",\n",
        "                        val_accuracy=f\"{val_accuracy:.4f}\",\n",
        "                    )\n",
        "\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "            monitor.stop()\n",
        "\n",
        "            if best_val_loss is None or val_loss < best_val_loss:\n",
        "                save_model(model, f\"{base_dir}/weights/best_{model_number}.pt\")\n",
        "                monitor.log(f\"Model saved as best_{model_number}.pt\\n\")\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        save_model(model, f\"{base_dir}/weights/last_{model_number}.pt\")\n",
        "\n",
        "        plot_training_metrics(\n",
        "            train_losses,\n",
        "            val_losses,\n",
        "            train_accuracies,\n",
        "            val_accuracies,\n",
        "            learning_rates,\n",
        "            model_number,\n",
        "            base_dir,\n",
        "        )\n",
        "\n",
        "    monitor.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c59678-ac85-40f7-9ad2-71d1b9f50bc5",
      "metadata": {
        "id": "78c59678-ac85-40f7-9ad2-71d1b9f50bc5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### TRAINING LOOP\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Baseline\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "#### TRAINING LOOP\n",
        "model.train()\n",
        "\n",
        "# DANN\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = [0.0, 0]\n",
        "    for batch_idx, ((src_x, src_y), (trg_x, _)) in tqdm(enumerate(zip(train_loader, test_loader))):\n",
        "        src_x, src_y = src_x.to(device), src_y.to(device)\n",
        "        trg_x = trg_x.to(device)\n",
        "\n",
        "        src_cls_o, src_dom_o = model(src_x)\n",
        "        _, trg_dom_o = model(trg_x)\n",
        "\n",
        "        if batch_idx % 2 == 0:\n",
        "            # Classification Loss\n",
        "            loss = F.cross_entropy(src_cls_o, src_y)\n",
        "\n",
        "        else:\n",
        "            # Classification Loss\n",
        "            cls_loss = F.cross_entropy(src_cls_o, src_y)\n",
        "\n",
        "            # Source Domain Adversarial Loss --> src_dom_label = 0\n",
        "            src_dom_label = torch.zeros(src_dom_o.size(0)).long().to(device)\n",
        "            src_dom_loss = F.cross_entropy(src_dom_o, src_dom_label)\n",
        "\n",
        "            # Target Domain Adversarial Loss --> trg_dom_label = 1\n",
        "            trg_dom_label = torch.ones(trg_dom_o.size(0)).long().to(device)\n",
        "            trg_dom_loss = F.cross_entropy(trg_dom_o, trg_dom_label)\n",
        "\n",
        "            # Final Loss\n",
        "            loss = cls_loss - LAMBDA * (src_dom_loss + trg_dom_loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss[0] += loss.item()\n",
        "        epoch_loss[1] += src_x.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f'[EPOCH {epoch+1}] Avg. Loss: {epoch_loss[0] / epoch_loss[1]}')\n",
        "# pip install wandb\n",
        "\n",
        "#### TEST LOOP\n",
        "model.eval()\n",
        "\n",
        "meter = Accuracy(task='multiclass', num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(test_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        cls_o, _ = model(x)\n",
        "        meter.update(cls_o, y)\n",
        "accuracy = meter.compute()\n",
        "\n",
        "print(f'\\nAccuracy on the target domain: {100 * accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
